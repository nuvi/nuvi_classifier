{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/award/Desktop/CS494/nuvi/env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding, LSTM\n",
    "from keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 35\n",
    "vocab_size = 2000\n",
    "char_model = False\n",
    "batch_size = 128\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data, get text list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('general.csv', sep=\"\\|\\|\\|\", engine='python')\n",
    "df.columns = ['Text', 'Feedback']\n",
    "text_list = df[u'Text'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=vocab_size, char_level=char_model)\n",
    "tokenizer.fit_on_texts(text_list)\n",
    "\n",
    "pickle.dump(tokenizer, open('general_tokenizer.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_matrix = tokenizer.texts_to_sequences(text_list)\n",
    "\n",
    "X = sequence.pad_sequences(text_matrix, maxlen=max_length, padding='pre', truncating='post')\n",
    "Y = np.array(df['Feedback'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 128, input_shape=(max_length, )))\n",
    "model.add(Dropout(.2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5764/5764 [==============================] - 13s 2ms/step - loss: 0.3144 - binary_accuracy: 0.8779\n",
      "Epoch 2/5\n",
      "5764/5764 [==============================] - 13s 2ms/step - loss: 0.1887 - binary_accuracy: 0.9259\n",
      "Epoch 3/5\n",
      "5764/5764 [==============================] - 13s 2ms/step - loss: 0.1461 - binary_accuracy: 0.9433\n",
      "Epoch 4/5\n",
      "5764/5764 [==============================] - 15s 3ms/step - loss: 0.1237 - binary_accuracy: 0.9540\n",
      "Epoch 5/5\n",
      "5764/5764 [==============================] - 16s 3ms/step - loss: 0.1038 - binary_accuracy: 0.9608\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=num_epochs)\n",
    "model.save('general_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General + Reviews Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data, get text list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('general+reviews.csv', sep=\"\\|\\|\\|\", engine='python')\n",
    "df.columns = ['Text', 'Feedback']\n",
    "text_list = df['Text'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=vocab_size, char_level=char_model)\n",
    "tokenizer.fit_on_texts(text_list)\n",
    "\n",
    "pickle.dump(tokenizer, open('general+reviews_tokenizer.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_matrix = tokenizer.texts_to_sequences(text_list)\n",
    "\n",
    "X = sequence.pad_sequences(text_matrix, maxlen=max_length, padding='pre', truncating='post')\n",
    "Y = np.array(df['Feedback'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 128, input_shape=(max_length, )))\n",
    "model.add(Dropout(.2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "9863/9863 [==============================] - 27s 3ms/step - loss: 0.2629 - binary_accuracy: 0.9005\n",
      "Epoch 2/5\n",
      "9863/9863 [==============================] - 22s 2ms/step - loss: 0.1565 - binary_accuracy: 0.9454\n",
      "Epoch 3/5\n",
      "9863/9863 [==============================] - 26s 3ms/step - loss: 0.1245 - binary_accuracy: 0.9550\n",
      "Epoch 4/5\n",
      "9863/9863 [==============================] - 21s 2ms/step - loss: 0.1015 - binary_accuracy: 0.9640\n",
      "Epoch 5/5\n",
      "9863/9863 [==============================] - 21s 2ms/step - loss: 0.0810 - binary_accuracy: 0.9708\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=num_epochs)\n",
    "model.save('general+reviews_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data, get text list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Start your mornings with @ikemorgan 'Down in A...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Please be specific in advertising for VIRAL LA...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you're worried about data privacy, maybe st...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@MomoPicks It looks like your original message...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@MomoPicks It looks like your original message...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Feedback\n",
       "0  Start your mornings with @ikemorgan 'Down in A...         0\n",
       "1  Please be specific in advertising for VIRAL LA...         0\n",
       "2  If you're worried about data privacy, maybe st...         1\n",
       "3  @MomoPicks It looks like your original message...         0\n",
       "4  @MomoPicks It looks like your original message...         0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('amazon.csv', sep=\"\\|\\|\\|\", engine='python')\n",
    "df.columns = ['Text', 'Feedback']\n",
    "text_list = df['Text'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=vocab_size, char_level=char_model)\n",
    "tokenizer.fit_on_texts(text_list)\n",
    "\n",
    "pickle.dump(tokenizer, open('amazon_tokenizer.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_matrix = tokenizer.texts_to_sequences(text_list)\n",
    "\n",
    "X = sequence.pad_sequences(text_matrix, maxlen=max_length, padding='pre', truncating='post')\n",
    "Y = np.array(df['Feedback'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 128, input_shape=(max_length, )))\n",
    "model.add(Dropout(.2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4049/4049 [==============================] - 11s 3ms/step - loss: 0.3202 - binary_accuracy: 0.8753: 1s - loss: 0.3264 - bina\n",
      "Epoch 2/5\n",
      "4049/4049 [==============================] - 10s 3ms/step - loss: 0.2270 - binary_accuracy: 0.9005\n",
      "Epoch 3/5\n",
      "4049/4049 [==============================] - 8s 2ms/step - loss: 0.1794 - binary_accuracy: 0.9286\n",
      "Epoch 4/5\n",
      "4049/4049 [==============================] - 9s 2ms/step - loss: 0.1456 - binary_accuracy: 0.9388\n",
      "Epoch 5/5\n",
      "4049/4049 [==============================] - 9s 2ms/step - loss: 0.1150 - binary_accuracy: 0.9543\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=num_epochs)\n",
    "model.save('amazon_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
